Test DPO by aligning Llama-3 using anthropic/HH_RLHF dataset

